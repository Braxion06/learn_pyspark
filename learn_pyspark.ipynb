{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d7fef7",
   "metadata": {},
   "source": [
    "# Learn and practice pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac02d5",
   "metadata": {},
   "source": [
    "## Prepare the  environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27771ef9",
   "metadata": {},
   "source": [
    "Import necessary modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b34bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a58f37c",
   "metadata": {},
   "source": [
    "Prepare the project's directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa52bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare directories\n",
    "os.makedirs(\"data/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860185e1",
   "metadata": {},
   "source": [
    "Download a subset of the NYC taxi trips dataset. This subset contains the trips of yellow taxis from march 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ca963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready\n"
     ]
    }
   ],
   "source": [
    "# Download NYC taxi trips dataset\n",
    "URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-03.parquet\"\n",
    "response = requests.get(url=URL, stream=True, timeout=(10, 30))\n",
    "\n",
    "if os.path.exists(\"data/yellow_taxi_data_202503.parquet\"):\n",
    "    print(\"Dataset ready\")\n",
    "else:\n",
    "    with open(\"data/yellow_taxi_data_202503.parquet\", \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=4092):\n",
    "            file.write(chunk)\n",
    "    print(\"Dataset downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4538bbd2",
   "metadata": {},
   "source": [
    "# Pyspark basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8048a6",
   "metadata": {},
   "source": [
    "Initialize Spark Session, this is the basic entrypoint to interact with Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce438ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/28 20:43:55 WARN Utils: Your hostname, xblade resolves to a loopback address: 127.0.1.1; using 192.168.10.156 instead (on interface enp2s0)\n",
      "25/06/28 20:43:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/28 20:43:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"LearnSpark\") \\\n",
    "    .config('spark.executor.memory', '4g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.sql.shuffle.partitions', '200') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03fb57",
   "metadata": {},
   "source": [
    "In the SparkSession builder we can configure the spark deployment and its process like the amount of memory and cores assigned to the executor process. The [configuration docs are Here](!https://spark.apache.org/docs/latest/configuration.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e024d56",
   "metadata": {},
   "source": [
    "## The Dataframe basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6bb5b",
   "metadata": {},
   "source": [
    "Create a Dataframe from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e954c127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Name: string, Age: bigint]\n"
     ]
    }
   ],
   "source": [
    "df_plain = spark.createDataFrame(data=[('Alan', 10), ('Cindy', 12)], schema=('Name', 'Age'))\n",
    "print(df_plain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a47ea7",
   "metadata": {},
   "source": [
    "Create a Dataframe by reading a file, it could be parquet, json, csv, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e1abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df: DataFrame = spark.read.parquet(\"data/yellow_taxi_data_202503.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a3ec8",
   "metadata": {},
   "source": [
    "Show the first rows of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e0103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|       1| 2025-03-01 00:17:16|  2025-03-01 00:25:52|              1|          0.9|         1|                 N|         140|         236|           1|        7.9|  3.5|    0.5|       2.6|         0.0|                  1.0|        15.5|                 2.5|        0.0|               0.0|\n",
      "|       1| 2025-03-01 00:37:38|  2025-03-01 00:43:51|              1|          0.6|         1|                 N|         140|         262|           1|        6.5|  3.5|    0.5|       2.3|         0.0|                  1.0|        13.8|                 2.5|        0.0|               0.0|\n",
      "|       2| 2025-03-01 00:24:35|  2025-03-01 00:39:49|              1|         1.94|         1|                 N|         161|          68|           1|       14.9|  1.0|    0.5|      5.16|         0.0|                  1.0|       25.81|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:56:16|  2025-03-01 01:01:35|              2|         0.95|         1|                 N|         231|          13|           1|        7.2|  1.0|    0.5|      2.59|         0.0|                  1.0|       15.54|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-03-01 00:01:44|  2025-03-01 00:10:00|              1|          1.5|         1|                 N|         163|         236|           1|        8.6| 4.25|    0.5|      2.85|         0.0|                  1.0|        17.2|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-03-01 00:11:57|  2025-03-01 00:28:33|              0|          2.0|         1|                 N|         166|          74|           1|       16.3|  1.0|    0.5|       2.0|         0.0|                  1.0|        20.8|                 0.0|        0.0|               0.0|\n",
      "|       2| 2025-03-01 00:22:35|  2025-03-01 00:34:06|              2|         3.27|         1|                 N|          88|          79|           1|       17.0|  1.0|    0.5|      4.55|         0.0|                  1.0|        27.3|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:37:22|  2025-03-01 00:45:03|              1|         0.95|         1|                 N|         114|         107|           1|        8.6|  1.0|    0.5|       2.0|         0.0|                  1.0|       16.35|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-02-28 23:50:41|  2025-03-01 00:03:51|              1|         2.09|         1|                 N|          79|         186|           1|       13.5|  1.0|    0.5|      3.85|         0.0|                  1.0|        23.1|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:06:48|  2025-03-01 00:18:44|              1|         1.43|         1|                 N|         186|         107|           1|       12.1|  1.0|    0.5|      3.57|         0.0|                  1.0|       21.42|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:27:25|  2025-03-01 00:34:41|              1|         0.89|         1|                 N|          79|         211|           1|        8.6|  1.0|    0.5|       0.0|         0.0|                  1.0|       14.35|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:39:38|  2025-03-01 00:43:49|              1|         0.72|         1|                 N|         211|         231|           1|        6.5|  1.0|    0.5|       2.0|         0.0|                  1.0|       14.25|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-03-01 00:44:28|  2025-03-01 01:25:34|              2|         18.6|         2|                 N|         132|          48|           2|       70.0|  5.0|    0.5|       0.0|        6.94|                  1.0|       83.44|                 2.5|       1.75|              0.75|\n",
      "|       2| 2025-03-01 00:00:15|  2025-03-01 01:03:30|              4|        23.28|         1|                 N|         132|         220|           2|      101.7|  1.0|    0.5|       0.0|        6.94|                  1.0|      112.89|                 0.0|       1.75|               0.0|\n",
      "|       2| 2025-03-01 00:02:02|  2025-03-01 00:18:45|              1|         2.73|         1|                 N|         163|         263|           1|       17.7|  1.0|    0.5|      4.69|         0.0|                  1.0|       28.14|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:21:17|  2025-03-01 00:25:33|              1|         1.29|         1|                 N|         141|         229|           1|        7.9|  1.0|    0.5|      2.05|         0.0|                  1.0|        15.7|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:41:51|  2025-03-01 00:50:56|              1|         1.99|         1|                 N|         211|         137|           1|       11.4|  1.0|    0.5|       1.0|         0.0|                  1.0|       18.15|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-03-01 00:29:44|  2025-03-01 00:35:25|              1|          0.9|         1|                 N|         246|          90|           1|        7.9| 4.25|    0.5|       2.7|         0.0|                  1.0|       16.35|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-03-01 00:41:30|  2025-03-01 00:53:25|              2|          2.4|         1|                 N|         249|         163|           1|       14.9| 4.25|    0.5|       4.1|         0.0|                  1.0|       24.75|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:06:21|  2025-03-01 00:12:06|              2|         0.59|         1|                 N|         186|          68|           2|        7.2|  1.0|    0.5|       0.0|         0.0|                  1.0|       12.95|                 2.5|        0.0|              0.75|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3be5a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|       1| 2025-03-01 00:17:16|  2025-03-01 00:25:52|              1|          0.9|         1|                 N|         140|         236|           1|        7.9|  3.5|    0.5|       2.6|         0.0|                  1.0|        15.5|                 2.5|        0.0|               0.0|\n",
      "|       1| 2025-03-01 00:37:38|  2025-03-01 00:43:51|              1|          0.6|         1|                 N|         140|         262|           1|        6.5|  3.5|    0.5|       2.3|         0.0|                  1.0|        13.8|                 2.5|        0.0|               0.0|\n",
      "|       2| 2025-03-01 00:24:35|  2025-03-01 00:39:49|              1|         1.94|         1|                 N|         161|          68|           1|       14.9|  1.0|    0.5|      5.16|         0.0|                  1.0|       25.81|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-01 00:56:16|  2025-03-01 01:01:35|              2|         0.95|         1|                 N|         231|          13|           1|        7.2|  1.0|    0.5|      2.59|         0.0|                  1.0|       15.54|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-03-01 00:01:44|  2025-03-01 00:10:00|              1|          1.5|         1|                 N|         163|         236|           1|        8.6| 4.25|    0.5|      2.85|         0.0|                  1.0|        17.2|                 2.5|        0.0|              0.75|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only the first 5 rows\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2dc77c",
   "metadata": {},
   "source": [
    "The Dataframe.head() Returns the first n rows like Pandas (1 by default on spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b6d26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=1, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 17, 16), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 0, 25, 52), passenger_count=1, trip_distance=0.9, RatecodeID=1, store_and_fwd_flag='N', PULocationID=140, DOLocationID=236, payment_type=1, fare_amount=7.9, extra=3.5, mta_tax=0.5, tip_amount=2.6, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=15.5, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.0),\n",
       " Row(VendorID=1, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 37, 38), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 0, 43, 51), passenger_count=1, trip_distance=0.6, RatecodeID=1, store_and_fwd_flag='N', PULocationID=140, DOLocationID=262, payment_type=1, fare_amount=6.5, extra=3.5, mta_tax=0.5, tip_amount=2.3, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=13.8, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.0),\n",
       " Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 24, 35), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 0, 39, 49), passenger_count=1, trip_distance=1.94, RatecodeID=1, store_and_fwd_flag='N', PULocationID=161, DOLocationID=68, payment_type=1, fare_amount=14.9, extra=1.0, mta_tax=0.5, tip_amount=5.16, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=25.81, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.75),\n",
       " Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 56, 16), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 1, 1, 35), passenger_count=2, trip_distance=0.95, RatecodeID=1, store_and_fwd_flag='N', PULocationID=231, DOLocationID=13, payment_type=1, fare_amount=7.2, extra=1.0, mta_tax=0.5, tip_amount=2.59, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=15.54, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.75),\n",
       " Row(VendorID=1, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 1, 44), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 0, 10), passenger_count=1, trip_distance=1.5, RatecodeID=1, store_and_fwd_flag='N', PULocationID=163, DOLocationID=236, payment_type=1, fare_amount=8.6, extra=4.25, mta_tax=0.5, tip_amount=2.85, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=17.2, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.75)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55779de0",
   "metadata": {},
   "source": [
    "The DataFrame.take() method works similarly to head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170fc189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=1, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 17, 16), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 0, 25, 52), passenger_count=1, trip_distance=0.9, RatecodeID=1, store_and_fwd_flag='N', PULocationID=140, DOLocationID=236, payment_type=1, fare_amount=7.9, extra=3.5, mta_tax=0.5, tip_amount=2.6, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=15.5, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.0),\n",
       " Row(VendorID=1, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 37, 38), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 0, 43, 51), passenger_count=1, trip_distance=0.6, RatecodeID=1, store_and_fwd_flag='N', PULocationID=140, DOLocationID=262, payment_type=1, fare_amount=6.5, extra=3.5, mta_tax=0.5, tip_amount=2.3, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=13.8, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.0),\n",
       " Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 24, 35), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 0, 39, 49), passenger_count=1, trip_distance=1.94, RatecodeID=1, store_and_fwd_flag='N', PULocationID=161, DOLocationID=68, payment_type=1, fare_amount=14.9, extra=1.0, mta_tax=0.5, tip_amount=5.16, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=25.81, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.75),\n",
       " Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 56, 16), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 1, 1, 35), passenger_count=2, trip_distance=0.95, RatecodeID=1, store_and_fwd_flag='N', PULocationID=231, DOLocationID=13, payment_type=1, fare_amount=7.2, extra=1.0, mta_tax=0.5, tip_amount=2.59, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=15.54, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.75),\n",
       " Row(VendorID=1, tpep_pickup_datetime=datetime.datetime(2025, 3, 1, 0, 1, 44), tpep_dropoff_datetime=datetime.datetime(2025, 3, 1, 0, 10), passenger_count=1, trip_distance=1.5, RatecodeID=1, store_and_fwd_flag='N', PULocationID=163, DOLocationID=236, payment_type=1, fare_amount=8.6, extra=4.25, mta_tax=0.5, tip_amount=2.85, tolls_amount=0.0, improvement_surcharge=1.0, total_amount=17.2, congestion_surcharge=2.5, Airport_fee=0.0, cbd_congestion_fee=0.75)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5265ef1",
   "metadata": {},
   "source": [
    "We can create a new Pandas Dataframe based on the original dataframe with Dataframe.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e1ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pd_df = df_plain.toPandas()\n",
    "print(type(pd_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0984cc",
   "metadata": {},
   "source": [
    "Show the DataFrame  with Pandas's Dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5abcc94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cindy</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age\n",
       "0   Alan   10\n",
       "1  Cindy   12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9aef9",
   "metadata": {},
   "source": [
    "Write a dataframe to csv files.\n",
    "The write.csv() method will create a directory and write multiple csv files(parts of the dataframe) that together, make up the whole dataframe and _SUCCESS files as confirmation.\n",
    "\n",
    "The .csv() method should be called after .option() and .mode() methods. In this case the header = true is used to write a header with the column names in the .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33ec944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.option('header', 'true').mode('overwrite').csv('data/yellow_taxi_data_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea083aa8",
   "metadata": {},
   "source": [
    "The df.write() method returns a **DataFrameWriter** object that has many modes:\n",
    "\n",
    "**append**: Append contents of this DataFrame to existing data.\n",
    "\n",
    "**overwrite**: Overwrite existing data.\n",
    "\n",
    "**error or errorifexists**: Throw an exception if data already exists.\n",
    "\n",
    "**ignore**: Silently ignore this operation if data already exists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a53d1e",
   "metadata": {},
   "source": [
    "Read the csv data as a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569c3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+--------------------+------------+--------------------+-----------+------------------+\n",
      "|     _c0|                 _c1|                 _c2|            _c3|          _c4|       _c5|               _c6|         _c7|         _c8|         _c9|       _c10| _c11|   _c12|      _c13|        _c14|                _c15|        _c16|                _c17|       _c18|              _c19|\n",
      "+--------+--------------------+--------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+--------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_date...|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surch...|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "|       2|2025-03-31T08:25:...|2025-03-31T08:31:...|              1|         0.92|         1|                 N|         164|         233|           1|        7.9|  0.0|    0.5|       1.0|         0.0|                 1.0|       13.65|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:35:...|2025-03-31T08:56:...|              1|        10.55|         1|                 N|         229|         138|           2|       42.9|  5.0|    0.5|       0.0|        6.94|                 1.0|       59.59|                 2.5|        0.0|              0.75|\n",
      "|       1|2025-03-31T08:45:...|2025-03-31T08:59:...|              1|          2.8|         1|                 N|          79|         162|           1|       14.9| 3.25|    0.5|       1.0|         0.0|                 1.0|       20.65|                 2.5|        0.0|              0.75|\n",
      "|       1|2025-03-31T08:12:...|2025-03-31T08:21:...|              1|          1.5|         1|                 N|         263|         163|           1|       11.4| 3.25|    0.5|       3.2|         0.0|                 1.0|       19.35|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:21:...|2025-03-31T08:33:...|              1|         1.57|         1|                 N|         224|         186|           1|       12.1|  0.0|    0.5|      1.15|         0.0|                 1.0|        18.0|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:43:...|2025-03-31T08:52:...|              1|         1.04|         1|                 N|         113|         107|           1|        9.3|  0.0|    0.5|      2.81|         0.0|                 1.0|       16.86|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:59:...|2025-03-31T09:12:...|              1|         1.64|         1|                 N|         107|         161|           1|       12.8|  0.0|    0.5|      4.39|         0.0|                 1.0|       21.94|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:35:...|2025-03-31T09:07:...|              1|         4.56|         1|                 N|         249|         229|           1|       29.6|  0.0|    0.5|      6.87|         0.0|                 1.0|       41.22|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:16:...|2025-03-31T08:24:...|              1|         1.53|         1|                 N|         229|         263|           1|       10.0|  0.0|    0.5|      2.95|         0.0|                 1.0|        17.7|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:28:...|2025-03-31T08:44:...|              1|         3.04|         1|                 N|         263|         230|           1|       18.4|  0.0|    0.5|      2.32|         0.0|                 1.0|       25.47|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:51:...|2025-03-31T09:00:...|              1|         0.84|         1|                 N|          50|          68|           1|        9.3|  0.0|    0.5|       0.0|         0.0|                 1.0|       14.05|                 2.5|        0.0|              0.75|\n",
      "|       1|2025-03-31T08:16:...|2025-03-31T08:23:...|              1|          0.8|         1|                 N|         262|         140|           1|        7.2|  2.5|    0.5|      2.25|         0.0|                 1.0|       13.45|                 2.5|        0.0|               0.0|\n",
      "|       1|2025-03-31T08:33:...|2025-03-31T08:38:...|              1|          0.6|         1|                 N|         262|         236|           1|        5.1|  2.5|    0.5|       2.0|         0.0|                 1.0|        11.1|                 2.5|        0.0|               0.0|\n",
      "|       1|2025-03-31T08:40:...|2025-03-31T08:45:...|              1|          0.5|         1|                 N|         263|         236|           1|        5.8|  2.5|    0.5|       2.0|         0.0|                 1.0|        11.8|                 2.5|        0.0|               0.0|\n",
      "|       1|2025-03-31T08:46:...|2025-03-31T08:53:...|              1|          0.7|         1|                 N|         236|         262|           1|        6.5|  2.5|    0.5|       2.1|         0.0|                 1.0|        12.6|                 2.5|        0.0|               0.0|\n",
      "|       1|2025-03-31T08:54:...|2025-03-31T09:08:...|              1|          1.8|         1|                 N|         262|         237|           1|       12.8| 3.25|    0.5|       1.0|         0.0|                 1.0|       18.55|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:36:...|2025-03-31T08:42:...|              3|         2.15|         1|                 N|         143|         246|           1|       11.4|  0.0|    0.5|       1.0|         0.0|                 1.0|       17.15|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:52:...|2025-03-31T09:01:...|              1|          1.5|         1|                 N|          68|         100|           1|       10.7|  0.0|    0.5|       2.0|         0.0|                 1.0|       17.45|                 2.5|        0.0|              0.75|\n",
      "|       2|2025-03-31T08:33:...|2025-03-31T08:40:...|              2|         0.99|         1|                 N|         230|          68|           1|        7.9|  0.0|    0.5|      2.53|         0.0|                 1.0|       15.18|                 2.5|        0.0|              0.75|\n",
      "+--------+--------------------+--------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+--------------------+------------+--------------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv = spark.read.csv('data/yellow_taxi_data_csv')\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837319c",
   "metadata": {},
   "source": [
    "The dataframe columns were not inferred, the header = true option must be called. The option inferSchema is useful too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9dfa9e",
   "metadata": {},
   "source": [
    "First let's check the current schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b28c4df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0f5a1",
   "metadata": {},
   "source": [
    "Now let's read again it using both options, passed as a dictionary with the **.options** method, this is different from **.option**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c998524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# we can also use the read.csv() method and pass parameter to it\n",
    "# df_csv = spark.read.csv('data/yellow_taxi_data_csv', header=true, inferschema=true)\n",
    "df_csv = spark.read.options(header=True, inferschema=True, delimiter=',').csv('data/yellow_taxi_data_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237720e",
   "metadata": {},
   "source": [
    "The columns's names are mapped now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f73325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|cbd_congestion_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "|       2| 2025-03-31 08:25:18|  2025-03-31 08:31:33|              1|         0.92|         1|                 N|         164|         233|           1|        7.9|  0.0|    0.5|       1.0|         0.0|                  1.0|       13.65|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-31 08:35:17|  2025-03-31 08:56:30|              1|        10.55|         1|                 N|         229|         138|           2|       42.9|  5.0|    0.5|       0.0|        6.94|                  1.0|       59.59|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-03-31 08:45:27|  2025-03-31 08:59:43|              1|          2.8|         1|                 N|          79|         162|           1|       14.9| 3.25|    0.5|       1.0|         0.0|                  1.0|       20.65|                 2.5|        0.0|              0.75|\n",
      "|       1| 2025-03-31 08:12:55|  2025-03-31 08:21:41|              1|          1.5|         1|                 N|         263|         163|           1|       11.4| 3.25|    0.5|       3.2|         0.0|                  1.0|       19.35|                 2.5|        0.0|              0.75|\n",
      "|       2| 2025-03-31 08:21:32|  2025-03-31 08:33:03|              1|         1.57|         1|                 N|         224|         186|           1|       12.1|  0.0|    0.5|      1.15|         0.0|                  1.0|        18.0|                 2.5|        0.0|              0.75|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f78c2e",
   "metadata": {},
   "source": [
    "And the dataframe has a different(and much better) schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67b2f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa6c0ed",
   "metadata": {},
   "source": [
    "The dataframe.schema Attribute holds the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d39cc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampType(), True), StructField('tpep_dropoff_datetime', TimestampType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', IntegerType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', IntegerType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('Airport_fee', DoubleType(), True), StructField('cbd_congestion_fee', DoubleType(), True)])\n"
     ]
    }
   ],
   "source": [
    "print(df_csv.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1dd39",
   "metadata": {},
   "source": [
    "We can create a schema definition using the StructType and StructField classes, the structfield constructor parameters are: StructField(name, dataType, nullable=True, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d54ebf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe schema:\n",
      "StructType([StructField('VendorID', IntegerType(), True), StructField('tpep_pickup_datetime', TimestampType(), True), StructField('tpep_dropoff_datetime', TimestampType(), True), StructField('passenger_count', IntegerType(), True), StructField('trip_distance', DoubleType(), True), StructField('RatecodeID', IntegerType(), True), StructField('store_and_fwd_flag', StringType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('payment_type', IntegerType(), True), StructField('fare_amount', DoubleType(), True), StructField('extra', DoubleType(), True), StructField('mta_tax', DoubleType(), True), StructField('tip_amount', DoubleType(), True), StructField('tolls_amount', DoubleType(), True), StructField('improvement_surcharge', DoubleType(), True), StructField('total_amount', DoubleType(), True), StructField('congestion_surcharge', DoubleType(), True), StructField('Airport_fee', DoubleType(), True), StructField('cbd_congestion_fee', DoubleType(), True)])\n"
     ]
    }
   ],
   "source": [
    "df_schema = StructType([\n",
    "    StructField(\"VendorID\", IntegerType(), True),\n",
    "    StructField(\"tpep_pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"tpep_dropoff_datetime\", TimestampType(), True),\n",
    "    StructField(\"passenger_count\", IntegerType(), True),\n",
    "    StructField(\"trip_distance\", DoubleType(), True),\n",
    "    StructField(\"RatecodeID\", IntegerType(), True),\n",
    "    StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "    StructField(\"PULocationID\", IntegerType(), True),\n",
    "    StructField(\"DOLocationID\", IntegerType(), True),\n",
    "    StructField(\"payment_type\", IntegerType(), True),\n",
    "    StructField(\"fare_amount\", DoubleType(), True),\n",
    "    StructField(\"extra\", DoubleType(), True),\n",
    "    StructField(\"mta_tax\", DoubleType(), True),\n",
    "    StructField(\"tip_amount\", DoubleType(), True),\n",
    "    StructField(\"tolls_amount\", DoubleType(), True),\n",
    "    StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "    StructField(\"total_amount\", DoubleType(), True),\n",
    "    StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "    StructField(\"Airport_fee\", DoubleType(), True),\n",
    "    StructField(\"cbd_congestion_fee\", DoubleType(), True)\n",
    "])\n",
    "print(f'Dataframe schema:\\n{df_schema}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d152896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.schema(schema=df_schema).csv('data/yellow_taxi_data_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35f25891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      " |-- cbd_congestion_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7b5be",
   "metadata": {},
   "source": [
    "We can print only the columns of the dataframe with the Dataframe.columns Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "102a5df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee', 'cbd_congestion_fee']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35992fb1",
   "metadata": {},
   "source": [
    "The DataFrame.dtypes Attribute can be useful if we only want the columans and their types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe98b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('VendorID', 'int'), ('tpep_pickup_datetime', 'timestamp_ntz'), ('tpep_dropoff_datetime', 'timestamp_ntz'), ('passenger_count', 'bigint'), ('trip_distance', 'double'), ('RatecodeID', 'bigint'), ('store_and_fwd_flag', 'string'), ('PULocationID', 'int'), ('DOLocationID', 'int'), ('payment_type', 'bigint'), ('fare_amount', 'double'), ('extra', 'double'), ('mta_tax', 'double'), ('tip_amount', 'double'), ('tolls_amount', 'double'), ('improvement_surcharge', 'double'), ('total_amount', 'double'), ('congestion_surcharge', 'double'), ('Airport_fee', 'double'), ('cbd_congestion_fee', 'double')]\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870f930",
   "metadata": {},
   "source": [
    "With a correct schema, we can use the DataFrame.summary() method to generate a new dataframe with the statistics of said DataFrame. Let's use the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "020d8325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/28 20:44:09 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+------------------+\n",
      "|summary|          VendorID|   passenger_count|    trip_distance|        RatecodeID|store_and_fwd_flag|      PULocationID|     DOLocationID|      payment_type|       fare_amount|             extra|           mta_tax|        tip_amount|      tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|        Airport_fee|cbd_congestion_fee|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+------------------+\n",
      "|  count|           4145257|           3228594|          4145257|           3228594|           3228594|           4145257|          4145257|           4145257|           4145257|           4145257|           4145257|           4145257|           4145257|              4145257|           4145257|             3228594|            3228594|           4145257|\n",
      "|   mean|1.8249437851501125|1.2911199116395558|6.584099784403299| 2.423492393283268|              NULL|161.76531346548597|161.2287341894604|0.9560951226908248|17.800342562597166|1.2209241091686227|0.4785716711895065| 2.858856020265468|0.4749764924103659|    0.957108570107958|26.265898046844185|  2.2193944175080547|0.13512275002679186|0.5364268126198207|\n",
      "| stddev|0.5490765912853165|0.7317499817376729| 626.407536754718|11.360100348918557|              NULL|  65.9219960487389| 70.1327954566159|0.7362719752636325| 29.10144097036428|1.8501915009119179|0.1365122801872657|3.8448975263552603|2.1027958622778935|   0.2721862120192103|  31.9560839230314|  0.9155161802746349|0.49965083191910353|0.3569130718580522|\n",
      "|    min|                 1|                 0|              0.0|                 1|                 N|                 1|                1|                 0|            -999.0|             -9.25|              -0.5|            -92.09|           -142.17|                 -1.0|           -1000.0|                -2.5|              -1.75|             -0.75|\n",
      "|    25%|                 2|                 1|             1.03|                 1|              NULL|               114|              107|                 1|               8.6|               0.0|               0.5|               0.0|               0.0|                  1.0|             15.66|                 2.5|                0.0|               0.0|\n",
      "|    50%|                 2|                 1|              1.8|                 1|              NULL|               161|              162|                 1|              13.5|               0.0|               0.5|              2.17|               0.0|                  1.0|             20.75|                 2.5|                0.0|              0.75|\n",
      "|    75%|                 2|                 1|             3.42|                 1|              NULL|               232|              233|                 1|             21.26|               2.5|               0.5|              3.93|               0.0|                  1.0|             29.45|                 2.5|                0.0|              0.75|\n",
      "|    max|                 7|                 9|        320136.29|                99|                 Y|               265|              265|                 4|          46263.88|              13.5|              10.5|             290.0|            916.87|                  1.0|          46269.44|                 2.5|               6.75|               1.5|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+---------------------+------------------+--------------------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57d424",
   "metadata": {},
   "source": [
    "If we only want the count here's the simple way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a029b339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 4145257\n"
     ]
    }
   ],
   "source": [
    "print(f'Count: {df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e197c",
   "metadata": {},
   "source": [
    "# Dataframe Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303910c8",
   "metadata": {},
   "source": [
    "## Select operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a81bc5",
   "metadata": {},
   "source": [
    "Select: Returns a dataframe with only the **selected** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d003497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----+----------+------------+\n",
      "|VendorID|fare_amount|extra|tip_amount|total_amount|\n",
      "+--------+-----------+-----+----------+------------+\n",
      "|       1|        7.9|  3.5|       2.6|        15.5|\n",
      "|       1|        6.5|  3.5|       2.3|        13.8|\n",
      "|       2|       14.9|  1.0|      5.16|       25.81|\n",
      "|       2|        7.2|  1.0|      2.59|       15.54|\n",
      "|       1|        8.6| 4.25|      2.85|        17.2|\n",
      "|       1|       16.3|  1.0|       2.0|        20.8|\n",
      "|       2|       17.0|  1.0|      4.55|        27.3|\n",
      "|       2|        8.6|  1.0|       2.0|       16.35|\n",
      "|       2|       13.5|  1.0|      3.85|        23.1|\n",
      "|       2|       12.1|  1.0|      3.57|       21.42|\n",
      "|       2|        8.6|  1.0|       0.0|       14.35|\n",
      "|       2|        6.5|  1.0|       2.0|       14.25|\n",
      "|       1|       70.0|  5.0|       0.0|       83.44|\n",
      "|       2|      101.7|  1.0|       0.0|      112.89|\n",
      "|       2|       17.7|  1.0|      4.69|       28.14|\n",
      "|       2|        7.9|  1.0|      2.05|        15.7|\n",
      "|       2|       11.4|  1.0|       1.0|       18.15|\n",
      "|       1|        7.9| 4.25|       2.7|       16.35|\n",
      "|       1|       14.9| 4.25|       4.1|       24.75|\n",
      "|       2|        7.2|  1.0|       0.0|       12.95|\n",
      "+--------+-----------+-----+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', 'fare_amount', 'extra', 'tip_amount', 'total_amount').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a4a2a",
   "metadata": {},
   "source": [
    "We can select columns with Pandas's style too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0ae98cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        15.5|\n",
      "|       1|        13.8|\n",
      "|       2|       25.81|\n",
      "|       2|       15.54|\n",
      "|       1|        17.2|\n",
      "|       1|        20.8|\n",
      "|       2|        27.3|\n",
      "|       2|       16.35|\n",
      "|       2|        23.1|\n",
      "|       2|       21.42|\n",
      "|       2|       14.35|\n",
      "|       2|       14.25|\n",
      "|       1|       83.44|\n",
      "|       2|      112.89|\n",
      "|       2|       28.14|\n",
      "|       2|        15.7|\n",
      "|       2|       18.15|\n",
      "|       1|       16.35|\n",
      "|       1|       24.75|\n",
      "|       2|       12.95|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['VendorID', 'total_amount'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703a696",
   "metadata": {},
   "source": [
    "Or an Attribute style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67e5f188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        15.5|\n",
      "|       1|        13.8|\n",
      "|       2|       25.81|\n",
      "|       2|       15.54|\n",
      "|       1|        17.2|\n",
      "|       1|        20.8|\n",
      "|       2|        27.3|\n",
      "|       2|       16.35|\n",
      "|       2|        23.1|\n",
      "|       2|       21.42|\n",
      "|       2|       14.35|\n",
      "|       2|       14.25|\n",
      "|       1|       83.44|\n",
      "|       2|      112.89|\n",
      "|       2|       28.14|\n",
      "|       2|        15.7|\n",
      "|       2|       18.15|\n",
      "|       1|       16.35|\n",
      "|       1|       24.75|\n",
      "|       2|       12.95|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.VendorID, df.total_amount).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8f2c8",
   "metadata": {},
   "source": [
    "Dataframe.limit(): Limits the result count of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34cd006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        15.5|\n",
      "|       1|        13.8|\n",
      "|       2|       25.81|\n",
      "|       2|       15.54|\n",
      "|       1|        17.2|\n",
      "|       1|        20.8|\n",
      "|       2|        27.3|\n",
      "|       2|       16.35|\n",
      "|       2|        23.1|\n",
      "|       2|       21.42|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.VendorID, df.total_amount).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd682d7f",
   "metadata": {},
   "source": [
    "DataFrame.collect() returns all the rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c8339a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=1, total_amount=15.5),\n",
       " Row(VendorID=1, total_amount=13.8),\n",
       " Row(VendorID=2, total_amount=25.81),\n",
       " Row(VendorID=2, total_amount=15.54),\n",
       " Row(VendorID=1, total_amount=17.2),\n",
       " Row(VendorID=1, total_amount=20.8),\n",
       " Row(VendorID=2, total_amount=27.3),\n",
       " Row(VendorID=2, total_amount=16.35),\n",
       " Row(VendorID=2, total_amount=23.1),\n",
       " Row(VendorID=2, total_amount=21.42)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(df.VendorID, df.total_amount).limit(10).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7bd4b0",
   "metadata": {},
   "source": [
    "We can return a column using the col() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "598f8f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        15.5|\n",
      "|       1|        13.8|\n",
      "|       2|       25.81|\n",
      "|       2|       15.54|\n",
      "|       1|        17.2|\n",
      "|       1|        20.8|\n",
      "|       2|        27.3|\n",
      "|       2|       16.35|\n",
      "|       2|        23.1|\n",
      "|       2|       21.42|\n",
      "|       2|       14.35|\n",
      "|       2|       14.25|\n",
      "|       1|       83.44|\n",
      "|       2|      112.89|\n",
      "|       2|       28.14|\n",
      "|       2|        15.7|\n",
      "|       2|       18.15|\n",
      "|       1|       16.35|\n",
      "|       1|       24.75|\n",
      "|       2|       12.95|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(col='VendorID'), col('total_amount')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940906ab",
   "metadata": {},
   "source": [
    "Dataframe Aliases (another name like in sql), they are useful to refer a column within a dataframe in joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acb89e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_as = df.alias('nyc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e190304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        15.5|\n",
      "|       1|        13.8|\n",
      "|       2|       25.81|\n",
      "|       2|       15.54|\n",
      "|       1|        17.2|\n",
      "|       1|        20.8|\n",
      "|       2|        27.3|\n",
      "|       2|       16.35|\n",
      "|       2|        23.1|\n",
      "|       2|       21.42|\n",
      "|       2|       14.35|\n",
      "|       2|       14.25|\n",
      "|       1|       83.44|\n",
      "|       2|      112.89|\n",
      "|       2|       28.14|\n",
      "|       2|        15.7|\n",
      "|       2|       18.15|\n",
      "|       1|       16.35|\n",
      "|       1|       24.75|\n",
      "|       2|       12.95|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_as.select(col('nyc.VendorID'), col('nyc.total_amount')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b797912",
   "metadata": {},
   "source": [
    "Columns Aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35fbec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|VendorID|TOTAL_ALIAS|\n",
      "+--------+-----------+\n",
      "|       1|       15.5|\n",
      "|       1|       13.8|\n",
      "|       2|      25.81|\n",
      "|       2|      15.54|\n",
      "|       1|       17.2|\n",
      "|       1|       20.8|\n",
      "|       2|       27.3|\n",
      "|       2|      16.35|\n",
      "|       2|       23.1|\n",
      "|       2|      21.42|\n",
      "|       2|      14.35|\n",
      "|       2|      14.25|\n",
      "|       1|      83.44|\n",
      "|       2|     112.89|\n",
      "|       2|      28.14|\n",
      "|       2|       15.7|\n",
      "|       2|      18.15|\n",
      "|       1|      16.35|\n",
      "|       1|      24.75|\n",
      "|       2|      12.95|\n",
      "+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', col('total_amount').alias('TOTAL_ALIAS')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16103b5",
   "metadata": {},
   "source": [
    "Sorting Data\n",
    "We can sort the data with the .sort() method, any number of columns can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b652bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|VendorID|TOTAL_ALIAS|\n",
      "+--------+-----------+\n",
      "|       1|   46269.44|\n",
      "|       1|     1009.0|\n",
      "|       1|    1003.62|\n",
      "|       1|     832.74|\n",
      "|       1|     602.75|\n",
      "|       1|     551.75|\n",
      "|       1|      547.2|\n",
      "|       1|     521.69|\n",
      "|       1|     516.69|\n",
      "|       1|     514.44|\n",
      "|       1|      512.0|\n",
      "|       1|     502.99|\n",
      "|       1|      501.0|\n",
      "|       1|      475.5|\n",
      "|       1|     472.45|\n",
      "|       1|     467.29|\n",
      "|       1|     451.98|\n",
      "|       1|      451.0|\n",
      "|       1|      451.0|\n",
      "|       1|     440.59|\n",
      "+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', col('total_amount').alias('TOTAL_ALIAS')) \\\n",
    "    .sort(['VendorID', 'TOTAL_ALIAS'], ascending=[True, False]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48abc98c",
   "metadata": {},
   "source": [
    "## Filter Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66cacf1",
   "metadata": {},
   "source": [
    "We can use the DataFrame.filter() or DataFrame.where() methods to filter the data, .where() is an alias for filter(). This methods are used alongside filter operators to create a column expression that represents a `Filter Condition`.\n",
    "\n",
    "Some Filter Operators:\n",
    "\n",
    "| Operation        | Example (Expression)                    | Equivalent SQL |\n",
    "| ---------------- | --------------------------------------- | ------------------- |\n",
    "| Equal to         | `col(\"age\") == 30`                      | `age = 30`          |\n",
    "| Not equal        | `col(\"age\") != 30`                      | `age <> 30`         |\n",
    "| Greater than     | `col(\"age\") > 18`                       | `age > 18`          |\n",
    "| Less than        | `col(\"age\") < 65`                       | `age < 65`          |\n",
    "| Greater or equal | `col(\"age\") >= 21`                      | `age >= 21`         |\n",
    "| Less or equal    | `col(\"age\") <= 65`                      | `age <= 65`         |\n",
    "| And              | `(col(\"age\") > 18) & (col(\"age\") < 65)` | `AND`               |\n",
    "| Or               | `(col(\"age\") > 18) \\| (col(\"age\") < 65)`| `OR`                |\n",
    "| Not              | `~(col(\"active\") == True)`              | `NOT active = true` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa634ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       2|      112.89|\n",
      "|       2|      153.85|\n",
      "|       2|      103.86|\n",
      "|       2|      100.13|\n",
      "|       1|      121.75|\n",
      "|       2|      106.97|\n",
      "|       1|      100.39|\n",
      "|       1|      101.89|\n",
      "|       2|      100.13|\n",
      "|       2|      148.26|\n",
      "|       2|      238.89|\n",
      "|       2|      104.21|\n",
      "|       1|      100.09|\n",
      "|       2|      103.86|\n",
      "|       2|      112.75|\n",
      "|       2|      145.83|\n",
      "|       2|      101.15|\n",
      "|       2|       124.2|\n",
      "|       2|      160.62|\n",
      "|       2|      103.86|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', 'total_amount').where('total_amount > 100').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "152c8e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        15.5|\n",
      "|       1|        13.8|\n",
      "|       1|        17.2|\n",
      "|       1|        20.8|\n",
      "|       1|       83.44|\n",
      "|       1|       16.35|\n",
      "|       1|       24.75|\n",
      "|       1|        55.0|\n",
      "|       1|       18.45|\n",
      "|       1|       19.15|\n",
      "|       1|       18.85|\n",
      "|       1|       14.35|\n",
      "|       1|        19.7|\n",
      "|       1|        15.5|\n",
      "|       1|        15.5|\n",
      "|       1|        25.6|\n",
      "|       1|        17.9|\n",
      "|       1|       17.95|\n",
      "|       1|       22.25|\n",
      "|       1|       20.55|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', 'total_amount').filter(df.VendorID == 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7a824",
   "metadata": {},
   "source": [
    "Multiple Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1c91882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+\n",
      "|VendorID|payment_type|total_amount|\n",
      "+--------+------------+------------+\n",
      "|       2|           2|     1694.31|\n",
      "|       2|           1|     1015.55|\n",
      "|       2|           2|     1059.21|\n",
      "|       2|           1|      1171.3|\n",
      "|       2|           1|      1081.2|\n",
      "|       2|           1|      1189.2|\n",
      "|       2|           1|     1175.52|\n",
      "|       2|           1|     1240.52|\n",
      "|       2|           2|     1183.39|\n",
      "|       2|           1|     1004.25|\n",
      "|       2|           1|     1004.25|\n",
      "|       2|           1|     1226.25|\n",
      "|       2|           1|      1249.3|\n",
      "|       2|           1|     2246.55|\n",
      "+--------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', 'payment_type', 'total_amount').filter((df.VendorID == 2) & (df.total_amount > 1000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6735a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------+\n",
      "|VendorID|payment_type|total_amount|\n",
      "+--------+------------+------------+\n",
      "|       2|           1|     1015.55|\n",
      "|       2|           1|      1171.3|\n",
      "|       2|           1|      1081.2|\n",
      "|       2|           1|      1189.2|\n",
      "|       2|           1|     1175.52|\n",
      "|       2|           1|     1240.52|\n",
      "|       2|           1|     1004.25|\n",
      "|       2|           1|     1004.25|\n",
      "|       2|           1|     1226.25|\n",
      "|       2|           1|      1249.3|\n",
      "|       2|           1|     2246.55|\n",
      "+--------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', 'payment_type', 'total_amount') \\\n",
    "    .filter((df.VendorID == 2) & (df.total_amount > 1000) & (df.payment_type == 1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a165598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       2|     1694.31|\n",
      "|       2|     1015.55|\n",
      "|       2|     1059.21|\n",
      "|       1|    46269.44|\n",
      "|       2|      1171.3|\n",
      "|       2|      1081.2|\n",
      "|       2|      1189.2|\n",
      "|       2|     1175.52|\n",
      "|       2|     1240.52|\n",
      "|       2|     1183.39|\n",
      "|       2|     1004.25|\n",
      "|       2|     1004.25|\n",
      "|       2|     1226.25|\n",
      "|       2|      1249.3|\n",
      "|       2|     2246.55|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', 'total_amount') \\\n",
    "    .filter(((df.VendorID == 2) & (df.total_amount > 1000)) | (df.total_amount > 2000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b414e",
   "metadata": {},
   "source": [
    "The Between operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c59546e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|VendorID|total_amount|\n",
      "+--------+------------+\n",
      "|       1|        15.5|\n",
      "|       2|       15.54|\n",
      "|       2|        15.7|\n",
      "|       2|       15.29|\n",
      "|       2|       15.93|\n",
      "|       1|        15.5|\n",
      "|       1|        15.5|\n",
      "|       2|       15.54|\n",
      "|       1|        15.0|\n",
      "|       2|       15.48|\n",
      "|       2|       15.75|\n",
      "|       2|       15.54|\n",
      "|       2|       15.75|\n",
      "|       1|        15.5|\n",
      "|       2|        15.8|\n",
      "|       2|       15.65|\n",
      "|       1|       15.75|\n",
      "|       2|       15.01|\n",
      "|       1|        15.5|\n",
      "|       2|       15.37|\n",
      "+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.VendorID, df.total_amount).where(df.total_amount.between(15, 16)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213842d7",
   "metadata": {},
   "source": [
    "Filtering null values can be done with .isnull(), .isNotNull() and .isNaN() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca307258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+\n",
      "|VendorID|Airport_fee|total_amount|\n",
      "+--------+-----------+------------+\n",
      "|       2|       NULL|        4.76|\n",
      "|       2|       NULL|       18.95|\n",
      "|       2|       NULL|         2.0|\n",
      "|       2|       NULL|        43.4|\n",
      "|       2|       NULL|       39.23|\n",
      "|       1|       NULL|       18.79|\n",
      "|       2|       NULL|        5.29|\n",
      "|       2|       NULL|       20.77|\n",
      "|       2|       NULL|       50.34|\n",
      "|       1|       NULL|       48.98|\n",
      "|       2|       NULL|       19.38|\n",
      "|       2|       NULL|        2.97|\n",
      "|       2|       NULL|       15.63|\n",
      "|       2|       NULL|         1.0|\n",
      "|       2|       NULL|       37.81|\n",
      "|       2|       NULL|       38.14|\n",
      "|       1|       NULL|        30.3|\n",
      "|       2|       NULL|       15.71|\n",
      "|       2|       NULL|        6.31|\n",
      "|       2|       NULL|       35.54|\n",
      "+--------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['VendorID', 'Airport_fee', 'total_amount'].where(col('Airport_fee').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1606d9b",
   "metadata": {},
   "source": [
    "Filter text in a column with .contains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce836b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+--------------------+\n",
      "|VendorID|Airport_fee|total_amount|tpep_pickup_datetime|\n",
      "+--------+-----------+------------+--------------------+\n",
      "|       1|       1.75|       57.25| 2025-03-05 00:17:44|\n",
      "|       1|        0.0|       16.35| 2025-03-05 00:02:33|\n",
      "|       2|        0.0|       14.44| 2025-03-05 00:17:56|\n",
      "|       2|        0.0|       19.25| 2025-03-05 00:39:48|\n",
      "|       2|        0.0|       17.16| 2025-03-05 00:20:42|\n",
      "|       2|        0.0|       16.32| 2025-03-05 00:00:03|\n",
      "|       2|        0.0|        30.6| 2025-03-05 00:13:04|\n",
      "|       2|        0.0|        -8.0| 2025-03-05 00:45:09|\n",
      "|       2|        0.0|         8.0| 2025-03-05 00:45:09|\n",
      "|       2|        0.0|       23.94| 2025-03-05 00:22:02|\n",
      "|       2|        0.0|       17.22| 2025-03-05 00:29:21|\n",
      "|       2|       1.75|       71.74| 2025-03-05 00:09:59|\n",
      "|       2|       1.75|      147.72| 2025-03-05 00:26:52|\n",
      "|       1|        0.0|       26.45| 2025-03-05 00:32:22|\n",
      "|       2|        0.0|        16.4| 2025-03-05 00:33:31|\n",
      "|       2|        0.0|       30.19| 2025-03-05 00:32:52|\n",
      "|       2|        0.0|       17.15| 2025-03-05 00:10:36|\n",
      "|       1|        0.0|        25.9| 2025-03-05 00:55:43|\n",
      "|       2|        0.0|       60.83| 2025-03-05 00:34:05|\n",
      "|       2|        0.0|       22.65| 2025-03-05 00:43:58|\n",
      "+--------+-----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['VendorID', 'Airport_fee', 'total_amount', 'tpep_pickup_datetime'] \\\n",
    "    .where(col('tpep_pickup_datetime').contains('2025-03-05')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c768adbf",
   "metadata": {},
   "source": [
    "SQL LIKE pattern filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24400cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+--------------------+\n",
      "|VendorID|Airport_fee|total_amount|tpep_pickup_datetime|\n",
      "+--------+-----------+------------+--------------------+\n",
      "|       2|        0.0|       18.15| 2025-03-01 00:41:51|\n",
      "|       2|        0.0|       38.99| 2025-03-01 00:51:48|\n",
      "|       2|        0.0|       18.06| 2025-03-01 00:51:23|\n",
      "|       2|        0.0|       48.56| 2025-03-01 00:44:51|\n",
      "|       1|        0.0|       26.45| 2025-03-01 00:16:51|\n",
      "|       1|        0.0|       18.55| 2025-03-01 00:56:51|\n",
      "|       1|        0.0|        14.0| 2025-03-01 00:51:04|\n",
      "|       2|        0.0|       21.42| 2025-03-01 00:51:30|\n",
      "|       2|        0.0|       16.38| 2025-03-01 00:51:14|\n",
      "|       2|        0.0|       51.09| 2025-03-01 00:02:51|\n",
      "|       2|        0.0|       14.95| 2025-03-01 00:22:51|\n",
      "|       2|        0.0|       25.62| 2025-03-01 00:03:51|\n",
      "|       2|        0.0|       15.65| 2025-03-01 00:51:35|\n",
      "|       2|        0.0|       26.46| 2025-03-01 00:51:47|\n",
      "|       2|        0.0|       21.75| 2025-03-01 00:50:51|\n",
      "|       2|        0.0|        35.7| 2025-03-01 00:27:51|\n",
      "|       2|        0.0|       16.23| 2025-03-01 00:20:51|\n",
      "|       2|        0.0|       25.62| 2025-03-01 00:51:18|\n",
      "|       2|        0.0|       34.02| 2025-03-01 00:11:51|\n",
      "|       2|        0.0|       15.65| 2025-03-01 00:51:24|\n",
      "+--------+-----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['VendorID', 'Airport_fee', 'total_amount', 'tpep_pickup_datetime'] \\\n",
    "    .where(col('tpep_pickup_datetime').like('%51%')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36fed5",
   "metadata": {},
   "source": [
    "Case insensitive SQL LIKE pattern filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a14dfdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|VendorID|store_and_fwd_flag|\n",
      "+--------+------------------+\n",
      "+--------+------------------+\n",
      "\n",
      "+--------+------------------+\n",
      "|VendorID|store_and_fwd_flag|\n",
      "+--------+------------------+\n",
      "|       1|                 N|\n",
      "|       1|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       1|                 N|\n",
      "|       1|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       1|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       2|                 N|\n",
      "|       1|                 N|\n",
      "|       1|                 N|\n",
      "|       2|                 N|\n",
      "+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.VendorID, df.store_and_fwd_flag).where(col('store_and_fwd_flag').like('n')).show()\n",
    "df.select(df.VendorID, df.store_and_fwd_flag).where(col('store_and_fwd_flag').ilike('n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e4a8c6",
   "metadata": {},
   "source": [
    "SQL LIKE pattern with REGEX filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "197568e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+--------------------+\n",
      "|VendorID|Airport_fee|total_amount|tpep_pickup_datetime|\n",
      "+--------+-----------+------------+--------------------+\n",
      "|       2|        0.0|       18.15| 2025-03-01 00:41:51|\n",
      "|       2|        0.0|       48.56| 2025-03-01 00:44:51|\n",
      "|       1|        0.0|       26.45| 2025-03-01 00:16:51|\n",
      "|       1|        0.0|       18.55| 2025-03-01 00:56:51|\n",
      "|       2|        0.0|       51.09| 2025-03-01 00:02:51|\n",
      "|       2|        0.0|       14.95| 2025-03-01 00:22:51|\n",
      "|       2|        0.0|       25.62| 2025-03-01 00:03:51|\n",
      "|       2|        0.0|       21.75| 2025-03-01 00:50:51|\n",
      "|       2|        0.0|        35.7| 2025-03-01 00:27:51|\n",
      "|       2|        0.0|       16.23| 2025-03-01 00:20:51|\n",
      "|       2|        0.0|       34.02| 2025-03-01 00:11:51|\n",
      "|       1|        0.0|        15.3| 2025-03-01 00:51:51|\n",
      "|       2|        0.0|       15.05| 2025-03-01 00:17:51|\n",
      "|       2|        0.0|        18.9| 2025-03-01 00:35:51|\n",
      "|       1|        0.0|       17.95| 2025-03-01 00:35:51|\n",
      "|       2|        0.0|       18.65| 2025-03-01 00:48:51|\n",
      "|       2|        0.0|        15.7| 2025-03-01 00:24:51|\n",
      "|       1|        0.0|       24.15| 2025-03-01 00:04:51|\n",
      "|       2|        0.0|       36.85| 2025-03-01 00:37:51|\n",
      "|       1|        0.0|       24.05| 2025-03-01 00:09:51|\n",
      "+--------+-----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['VendorID', 'Airport_fee', 'total_amount', 'tpep_pickup_datetime'] \\\n",
    "    .where(col('tpep_pickup_datetime').rlike('.51$')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e646a4b",
   "metadata": {},
   "source": [
    "Startswith, filter strings that starts with the specified string filter without using LIKE or REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5bfb1b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+------------+--------------------+\n",
      "|VendorID|Airport_fee|total_amount|tpep_pickup_datetime|\n",
      "+--------+-----------+------------+--------------------+\n",
      "|       2|        0.0|        27.3| 2025-03-30 23:59:06|\n",
      "|       2|        0.0|       20.58| 2025-03-30 23:00:05|\n",
      "|       1|       1.75|        71.0| 2025-03-30 23:18:41|\n",
      "|       2|       1.75|       53.05| 2025-03-30 23:55:58|\n",
      "|       1|       1.75|        91.8| 2025-03-30 23:05:01|\n",
      "|       1|        0.0|       12.25| 2025-03-30 23:48:17|\n",
      "|       2|        0.0|       26.46| 2025-03-30 23:00:27|\n",
      "|       2|        0.0|        14.7| 2025-03-30 23:48:30|\n",
      "|       1|        0.0|        19.7| 2025-03-30 23:33:25|\n",
      "|       1|        0.0|       14.35| 2025-03-30 23:07:44|\n",
      "|       1|        0.0|       13.65| 2025-03-30 23:17:18|\n",
      "|       2|        0.0|       24.15| 2025-03-30 23:22:33|\n",
      "|       1|        0.0|        11.5| 2025-03-30 23:04:25|\n",
      "|       2|        0.0|       29.58| 2025-03-30 23:01:48|\n",
      "|       1|        0.0|       17.15| 2025-03-30 23:03:07|\n",
      "|       1|        0.0|        33.5| 2025-03-30 23:59:23|\n",
      "|       2|       1.75|      234.69| 2025-03-30 23:51:00|\n",
      "|       1|       1.75|       76.49| 2025-03-30 23:24:34|\n",
      "|       2|        0.0|       20.65| 2025-03-30 23:07:40|\n",
      "|       2|        0.0|       21.35| 2025-03-30 23:08:41|\n",
      "+--------+-----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['VendorID', 'Airport_fee', 'total_amount', 'tpep_pickup_datetime'] \\\n",
    "    .where(col('tpep_pickup_datetime').startswith('2025-03-30 23')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7338e51",
   "metadata": {},
   "source": [
    "Filter unique rows, just like `select distinct`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5aca3baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|VendorID|\n",
      "+--------+\n",
      "|       1|\n",
      "|       7|\n",
      "|       2|\n",
      "|       6|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66bbd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e507445",
   "metadata": {},
   "source": [
    "## Handling columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfaf2bf",
   "metadata": {},
   "source": [
    "Create columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dcf3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228f28f8",
   "metadata": {},
   "source": [
    "Columns Aliases refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4549ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|VendorID|TOTAL_ALIAS|\n",
      "+--------+-----------+\n",
      "|       1|       15.5|\n",
      "|       1|       13.8|\n",
      "|       2|      25.81|\n",
      "|       2|      15.54|\n",
      "|       1|       17.2|\n",
      "|       1|       20.8|\n",
      "|       2|       27.3|\n",
      "|       2|      16.35|\n",
      "|       2|       23.1|\n",
      "|       2|      21.42|\n",
      "|       2|      14.35|\n",
      "|       2|      14.25|\n",
      "|       1|      83.44|\n",
      "|       2|     112.89|\n",
      "|       2|      28.14|\n",
      "|       2|       15.7|\n",
      "|       2|      18.15|\n",
      "|       1|      16.35|\n",
      "|       1|      24.75|\n",
      "|       2|      12.95|\n",
      "+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', col('total_amount').alias('TOTAL_ALIAS')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d7370",
   "metadata": {},
   "source": [
    "Drop columns: The Dataframe.Drop() method returns a new dataframe without the columns specified in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fb7917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|VendorID|\n",
      "+--------+\n",
      "|       1|\n",
      "|       1|\n",
      "|       2|\n",
      "|       2|\n",
      "|       1|\n",
      "|       1|\n",
      "|       2|\n",
      "|       2|\n",
      "|       2|\n",
      "|       2|\n",
      "|       2|\n",
      "|       2|\n",
      "|       1|\n",
      "|       2|\n",
      "|       2|\n",
      "|       2|\n",
      "|       2|\n",
      "|       1|\n",
      "|       1|\n",
      "|       2|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', 'total_amount').drop('total_amount').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5982b",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acce831",
   "metadata": {},
   "source": [
    "Group By functions: COUNT, SUM, MIN, MAX, AVG, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccbf02c",
   "metadata": {},
   "source": [
    "Dataframe.GroupBy returns a DataFrameGroupBy class that is used to create aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2940f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupedData[grouping expressions: [VendorID], value: [VendorID: int, tpep_pickup_datetime: timestamp_ntz ... 18 more fields], type: GroupBy]\n"
     ]
    }
   ],
   "source": [
    "print(df.groupBy('VendorID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff906f",
   "metadata": {},
   "source": [
    "Count Aggregation: counts the rows by the groupby class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db7f28c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|VendorID|  count|\n",
      "+--------+-------+\n",
      "|       1| 834394|\n",
      "|       7|  21481|\n",
      "|       2|3289048|\n",
      "|       6|    334|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('VendorID').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67edcb",
   "metadata": {},
   "source": [
    "Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cacd692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------------+------------------+-------------------------+-------------------+-----------------------+\n",
      "|VendorID|avg(VendorID)|avg(passenger_count)|avg(trip_distance)|   avg(RatecodeID)| avg(PULocationID)| avg(DOLocationID)| avg(payment_type)|  avg(fare_amount)|        avg(extra)|       avg(mta_tax)|   avg(tip_amount)|  avg(tolls_amount)|avg(improvement_surcharge)| avg(total_amount)|avg(congestion_surcharge)|   avg(Airport_fee)|avg(cbd_congestion_fee)|\n",
      "+--------+-------------+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------------+------------------+-------------------------+-------------------+-----------------------+\n",
      "|       1|          1.0|  1.1356357489615063| 3.424591979328704| 7.168901724390824|163.15342152508288|162.15397761728872|0.9883723996097766|  18.4322967087491|3.1941489751843832|0.49553396836506497|2.8565741723933864|0.49396246857008635|        0.9520118792800524| 26.81411121125252|        2.206140107288467|0.10320747516088286|     0.5323752927274166|\n",
      "|       7|          7.0|   1.293608305013733| 2.988788696988037|1.0349611284390856| 170.7460546529491|167.22908616917275|1.1509240724361063|15.903308970718298|               0.0|                0.5| 3.557886038825003| 0.3956719891997602|                       1.0|25.361795540244803|        2.400726223173968|0.27089055444346166|     0.5585633815930358|\n",
      "|       2|          2.0|  1.3346868170868706| 7.408857827552657|1.1050775002854412| 161.3580844669947|160.95823867575055|0.9467313946163145|17.653924007798313|0.7284373685029834| 0.4741264037496564|2.8551598000390745| 0.4705445101440829|        0.9581881444113919| 26.13239850861697|       2.2215550837680156|0.14290554809904132|     0.5373645352697802|\n",
      "|       6|          6.0|                NULL| 9.088413173652697|              NULL|126.58982035928143|127.58083832335329|               0.0|2.9173652694610643|               0.0|                0.5|               0.0|   1.78862275449102|        0.2999999999999982|29.504341317365295|                     NULL|               NULL|                    0.0|\n",
      "+--------+-------------+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+------------------+-------------------+--------------------------+------------------+-------------------------+-------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy('VendorID').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe1327",
   "metadata": {},
   "source": [
    "The last output showed every column, remember to select first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2956eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|VendorID| avg(total_amount)|\n",
      "+--------+------------------+\n",
      "|       1| 26.81411121125252|\n",
      "|       7|25.361795540244803|\n",
      "|       2| 26.13239850861697|\n",
      "|       6|29.504341317365295|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('VendorID', 'total_amount').groupBy('VendorID').mean('total_amount').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5918b28",
   "metadata": {},
   "source": [
    "Grouping without .select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c849ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|VendorID| avg(total_amount)|\n",
      "+--------+------------------+\n",
      "|       1| 26.81411121125252|\n",
      "|       7|25.361795540244803|\n",
      "|       2| 26.13239850861697|\n",
      "|       6|29.504341317365295|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('VendorID').mean('total_amount').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51371365",
   "metadata": {},
   "source": [
    "We can compute multiple aggregations across the entire dataframe with the .agg() method, this is also an alias for DataFrame.groupBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61020a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+---------------+----------+------------------+\n",
      "|min(trip_distance)|sum(tolls_amount)|count(VendorID)|max(extra)| avg(total_amount)|\n",
      "+------------------+-----------------+---------------+----------+------------------+\n",
      "|               0.0|1968899.629999516|        4145257|      13.5|26.265898046844185|\n",
      "+------------------+-----------------+---------------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({ 'total_amount': 'avg', 'trip_distance': 'min', 'extra': 'max', \\\n",
    "        'VendorID': 'count', 'tolls_amount': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e4396",
   "metadata": {},
   "source": [
    "## Join and Union operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29809a80",
   "metadata": {},
   "source": [
    "Spark has **join types**, just like SQL, these are the ways that we can **join** (mix and match) the data between DataFrames(tables). Some examples: Inner, left, right, full outer, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4905f11",
   "metadata": {},
   "source": [
    "Spark also has **Join Srategies** these are the ways or algorithms used to shuffle, mix and match the data across nodes and executors in the spark cluster. Examples: Broadcast, sort merge, shuffle, etc; we can read about these in the [performance tuning documentation](!https://spark.apache.org/docs/latest/sql-performance-tuning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83628f93",
   "metadata": {},
   "source": [
    "We can join dataframes using `DataFrame.join(other, on=None, how=None)`, `inner` is the default value of the `how` parameter, and `other` is the  right side dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f8907ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+------------+\n",
      "|VendorID|trip_distance|total_amount|\n",
      "+--------+-------------+------------+\n",
      "|       1|          0.9|        15.5|\n",
      "+--------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframes\n",
    "df_a = df.select(df.VendorID, df.trip_distance).limit(1)\n",
    "df_b = df.select(df.VendorID, df.total_amount).limit(1)\n",
    "df_join = df_a.join(df_b, 'VendorID', 'inner')\n",
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e24347",
   "metadata": {},
   "source": [
    "Union concatenates DataFrames with the same schema, using the column's position, like SQL UNION, but with the caveat that there isn't automatic deduplication of rows, this makes spark's union closer to SQL UNION ALL, the SQL UNION behavior can be archieved with .union().distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02ef5d",
   "metadata": {},
   "source": [
    "In this example both dataframes have integer and double columns, making union possible, the output columns are VendorID and trip_distance because df_a was the main DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1b24d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|VendorID|trip_distance|\n",
      "+--------+-------------+\n",
      "|       1|          0.9|\n",
      "|       1|         15.5|\n",
      "+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_union = df_a.union(df_b)\n",
    "df_union.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9885de",
   "metadata": {},
   "source": [
    ".unionAll() ALL is an alias to .union() in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7eb58f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal spark Union (SQL Union All): 3\n",
      "Deduplicated spark Union (Union): 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Normal spark Union (SQL Union All): {df_a.unionAll(df_union).count()}')\n",
    "print(f'Deduplicated spark Union (Union): {df_a.unionAll(df_union).distinct().count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f05e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e02f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "571dd5b3",
   "metadata": {},
   "source": [
    "Shut down the current SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2779491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
